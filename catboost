import optuna
from catboost import CatBoostClassifier, Pool
import numpy as np

# Assuming X_train, y_train, X_valid, y_valid are your training data, labels, and validation sets

def objective(trial):
    param = {
        'iterations': trial.suggest_int('iterations', 100, 1000),
        'depth': trial.suggest_int('depth', 4, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'random_strength': trial.suggest_int('random_strength', 1, 20),
        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),
        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 30),
        'border_count': trial.suggest_int('border_count', 32, 255),
        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),
        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS', 'No']),
    }

    if param['bootstrap_type'] == 'Bayesian':
        param['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0, 1)

    if param['grow_policy'] == 'Lossguide':
        param['max_leaves'] = trial.suggest_int('max_leaves', 31, 64)

    if param['bootstrap_type'] in ['Bernoulli', 'MVS']:
        param['subsample'] = trial.suggest_float('subsample', 0.5, 1)

    model = CatBoostClassifier(**param, verbose=0)

    # You may need to create a Pool object if you have categorical features
    train_pool = Pool(X_train, y_train) # , cat_features=cat_features if you have categorical features
    
    model.fit(train_pool)

    preds = model.predict(X_valid)
    accuracy = np.mean(preds == y_valid)
    
    return accuracy

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)  # You can adjust the number of trials

print('Number of finished trials:', len(study.trials))
print('Best trial:', study.best_trial.params)
